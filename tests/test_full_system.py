"""Full System Integration Test - Complete End-to-End Validation

This test suite validates EVERY feature of the B2B Content Agent System:
- All 10 agents across 3 crews
- All 38 tools
- Complete workflow from product input to polished content
- Real document parsing, web scraping, content generation, and review

Expected time: 1.7 - 2.5 hours
Cost: ~$0.40 - $0.60 (depending on content volume)

This is the gold standard test - run before production deployment.
"""

import os
import sys
import time
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# Add src to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

# Load environment variables
from dotenv import load_dotenv
load_dotenv(project_root / ".env")

# Ensure we have API key
if not os.getenv("GOOGLE_API_KEY"):
    print("‚ùå ERROR: GOOGLE_API_KEY environment variable not set")
    print("Please set your API key in .env file")
    sys.exit(1)


class SystemTestRunner:
    """Comprehensive system test runner with automatic retry and error handling"""
    
    def __init__(self):
        self.test_results = {
            "start_time": datetime.now().isoformat(),
            "crews": {},
            "tools_tested": set(),
            "errors": [],
            "warnings": []
        }
        self.output_dir = project_root / "test_output"
        self.output_dir.mkdir(exist_ok=True)
        
    def log(self, message: str, level: str = "INFO"):
        """Log message with timestamp"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        prefix = {
            "INFO": "‚ÑπÔ∏è ",
            "SUCCESS": "‚úÖ",
            "WARNING": "‚ö†Ô∏è ",
            "ERROR": "‚ùå",
            "TEST": "üß™"
        }.get(level, "")
        
        print(f"[{timestamp}] {prefix} {message}")
        
    def retry_with_backoff(self, func, max_retries=3, initial_delay=5):
        """Retry function with exponential backoff for API overload"""
        for attempt in range(max_retries):
            try:
                return func()
            except Exception as e:
                error_msg = str(e)
                if "503" in error_msg or "overload" in error_msg.lower():
                    if attempt < max_retries - 1:
                        delay = initial_delay * (2 ** attempt)
                        self.log(f"API overloaded. Retrying in {delay}s... (attempt {attempt + 1}/{max_retries})", "WARNING")
                        time.sleep(delay)
                    else:
                        self.log(f"Max retries reached. Error: {error_msg}", "ERROR")
                        raise
                else:
                    # Not a rate limit error, raise immediately
                    raise
    
    def test_crew1_full(self) -> Dict[str, Any]:
        """Test CREW 1: Research & Planning with real inputs"""
        
        self.log("="*80, "INFO")
        self.log("CREW 1: RESEARCH & PLANNING - FULL TEST", "TEST")
        self.log("="*80, "INFO")
        self.log("Expected time: 30-45 minutes", "INFO")
        self.log("Testing: Product analysis, persona generation (20-30), content strategy", "INFO")
        self.log("="*80 + "\n", "INFO")
        
        from b2b_content_agent.crew import ResearchPlanningCrew
        
        # Create test input with real product information
        test_input = {
            "input_sources": """
            Product: Friend AI - Advanced AI-Powered Sales Assistant
            
            Overview:
            Friend AI is a revolutionary sales automation platform that uses advanced AI to help 
            B2B sales teams automate follow-ups, personalize outreach, and dramatically improve 
            close rates. Our platform integrates seamlessly with existing CRM systems and uses 
            natural language processing to craft personalized, context-aware follow-up messages.
            
            Key Features:
            1. Intelligent Follow-Up Automation - Never miss a follow-up again
            2. AI-Powered Personalization - Each message is customized to the prospect
            3. CRM Integration - Works with Salesforce, HubSpot, Pipedrive, and more
            4. Sentiment Analysis - Understand prospect engagement levels
            5. Meeting Scheduler - AI books meetings based on availability
            6. Performance Analytics - Track ROI and team productivity
            
            Target Markets:
            - B2B SaaS companies (10-500 employees)
            - Professional services firms
            - Technology companies
            - Manufacturing companies selling B2B
            - Consulting firms
            
            Value Propositions:
            - Increase close rates by 35-50%
            - Save 10+ hours per week per rep
            - Improve response rates by 3x
            - Never lose a deal due to poor follow-up
            - Scale personalization without scaling headcount
            
            Pricing:
            - Starter: $99/user/month (up to 5 users)
            - Professional: $199/user/month (5-20 users)
            - Enterprise: Custom pricing (20+ users)
            
            Technical Specs:
            - Cloud-based SaaS platform
            - REST API for custom integrations
            - SOC 2 Type II certified
            - 99.9% uptime SLA
            - GDPR and CCPA compliant
            """,
            "product_name": "Friend AI",
            "product_description": "AI-powered sales automation platform for B2B teams",
            "target_content_type": "case_study"
        }
        
        start_time = time.time()
        
        try:
            self.log("Starting CREW 1...", "INFO")
            crew = ResearchPlanningCrew()
            
            # Run with retry logic
            result = self.retry_with_backoff(
                lambda: crew.crew().kickoff(inputs=test_input)
            )
            
            elapsed = time.time() - start_time
            
            self.log(f"CREW 1 COMPLETED in {elapsed/60:.1f} minutes", "SUCCESS")
            
            # Save output
            output_file = self.output_dir / "crew1_result.txt"
            with open(output_file, "w") as f:
                f.write(str(result.raw if hasattr(result, 'raw') else result))
            
            self.log(f"Output saved to: {output_file}", "INFO")
            
            # Track tools used
            tools_used = [
                "DocumentParserTool", "ProductAnalyzerTool", "CompetitorAnalyzerTool",
                "IndustryAnalyzerTool", "JobRoleAnalyzerTool", "DemographicsMapperTool",
                "ContentTypeMatcherTool", "PersonaContentMapperTool", "StrategyTemplateGeneratorTool"
            ]
            self.tools_tested.update(tools_used)
            
            crew1_result = {
                "status": "PASSED",
                "time": elapsed,
                "output_size": len(str(result)),
                "tools_tested": tools_used
            }
            
            self.test_results["crews"]["crew1"] = crew1_result
            
            return {"success": True, "result": result, "time": elapsed}
            
        except Exception as e:
            elapsed = time.time() - start_time
            self.log(f"CREW 1 FAILED after {elapsed:.1f}s: {e}", "ERROR")
            
            import traceback
            error_details = traceback.format_exc()
            self.log(f"Error details:\n{error_details}", "ERROR")
            
            self.test_results["crews"]["crew1"] = {
                "status": "FAILED",
                "time": elapsed,
                "error": str(e)
            }
            self.test_results["errors"].append({
                "crew": "CREW1",
                "error": str(e),
                "traceback": error_details
            })
            
            return {"success": False, "error": str(e), "time": elapsed}
    
    def test_crew2_full(self, crew1_result=None) -> Dict[str, Any]:
        """Test CREW 2: Content Generation with all 4 agents"""
        
        self.log("\n" + "="*80, "INFO")
        self.log("CREW 2: CONTENT GENERATION - FULL TEST", "TEST")
        self.log("="*80, "INFO")
        self.log("Expected time: 48-67 minutes", "INFO")
        self.log("Testing: All 4 content writers (case study, white paper, pitch deck, social)", "INFO")
        self.log("="*80 + "\n", "INFO")
        
        from b2b_content_agent.content_generation_crew import ContentGenerationCrew
        
        # Use CREW 1 result if available, otherwise use sample data
        if crew1_result and crew1_result.get("success"):
            result_text = str(crew1_result["result"].raw if hasattr(crew1_result["result"], 'raw') else crew1_result["result"])
            
            test_input = {
                "persona_profile": result_text[:2000],  # First 2000 chars as persona
                "content_strategy": result_text,
                "product_analysis": result_text,
                "content_type": "case_study",
                "word_count_target": 1500
            }
        else:
            # Fallback test data
            test_input = {
                "persona_profile": """
                Persona: Sarah Chen, VP of Sales at TechCorp
                - Mid-market B2B SaaS company (150 employees)
                - Managing team of 25 sales reps
                - Challenges: Inconsistent follow-ups, low response rates, manual processes
                - Goals: Increase close rates, improve team productivity, scale without adding headcount
                - Budget authority: Up to $500K annually for sales tools
                """,
                "content_strategy": """
                Content Strategy: Create case study showing 40% close rate improvement
                Focus on quantifiable ROI, team productivity gains, and automation benefits
                Target executive buyers who value data-driven decisions
                """,
                "product_analysis": """
                Friend AI - AI-powered sales automation platform
                Key features: Intelligent follow-ups, AI personalization, CRM integration
                Value: 35-50% close rate increase, 10+ hours saved per week per rep
                """,
                "content_type": "case_study",
                "word_count_target": 1500
            }
        
        start_time = time.time()
        
        try:
            self.log("Starting CREW 2...", "INFO")
            crew = ContentGenerationCrew()
            
            # Run with retry logic
            result = self.retry_with_backoff(
                lambda: crew.crew().kickoff(inputs=test_input)
            )
            
            elapsed = time.time() - start_time
            
            self.log(f"CREW 2 COMPLETED in {elapsed/60:.1f} minutes", "SUCCESS")
            
            # Save output
            output_file = self.output_dir / "crew2_result.txt"
            with open(output_file, "w") as f:
                f.write(str(result.raw if hasattr(result, 'raw') else result))
            
            self.log(f"Output saved to: {output_file}", "INFO")
            
            # Track tools used
            tools_used = [
                "NarrativeStructureTool", "DataPointExtractorTool", "QuoteGeneratorTool",
                "TechnicalWritingTool", "ResearchSynthesizerTool", "CitationGeneratorTool",
                "VisualConceptTool", "ExecutiveSummaryTool", "DataVisualizationTool",
                "PlatformOptimizerTool", "HashtagGeneratorTool", "EngagementAnalyzerTool",
                "ThreadComposerTool", "VisualContentSuggestionTool", "CTAGeneratorTool", "PostSchedulerTool"
            ]
            self.tools_tested.update(tools_used)
            
            crew2_result = {
                "status": "PASSED",
                "time": elapsed,
                "output_size": len(str(result)),
                "tools_tested": tools_used
            }
            
            self.test_results["crews"]["crew2"] = crew2_result
            
            return {"success": True, "result": result, "time": elapsed}
            
        except Exception as e:
            elapsed = time.time() - start_time
            self.log(f"CREW 2 FAILED after {elapsed/60:.1f} minutes: {e}", "ERROR")
            
            import traceback
            error_details = traceback.format_exc()
            self.log(f"Error details:\n{error_details}", "ERROR")
            
            self.test_results["crews"]["crew2"] = {
                "status": "FAILED",
                "time": elapsed,
                "error": str(e)
            }
            self.test_results["errors"].append({
                "crew": "CREW2",
                "error": str(e),
                "traceback": error_details
            })
            
            return {"success": False, "error": str(e), "time": elapsed}
    
    def test_crew3_full(self, crew2_result=None) -> Dict[str, Any]:
        """Test CREW 3: Review & Polish with all review agents"""
        
        self.log("\n" + "="*80, "INFO")
        self.log("CREW 3: REVIEW & POLISH - FULL TEST", "TEST")
        self.log("="*80, "INFO")
        self.log("Expected time: 24-36 minutes", "INFO")
        self.log("Testing: QA review, brand review, SEO optimization", "INFO")
        self.log("="*80 + "\n", "INFO")
        
        from b2b_content_agent.review_polish_crew import ReviewPolishCrew
        
        # Use CREW 2 result if available, otherwise use sample content
        if crew2_result and crew2_result.get("success"):
            content = str(crew2_result["result"].raw if hasattr(crew2_result["result"], 'raw') else crew2_result["result"])
        else:
            # Fallback test content
            content = """
            Case Study: How TechCorp Increased Close Rates by 40% with Friend AI
            
            Executive Summary:
            TechCorp, a mid-market B2B SaaS company, struggled with inconsistent sales follow-ups
            and low response rates. After implementing Friend AI, they achieved a 40% increase in
            close rates and saved their sales team 250+ hours per month.
            
            The Challenge:
            Sarah Chen, VP of Sales at TechCorp, managed a team of 25 sales representatives handling
            200+ active deals at any given time. The team struggled with:
            - Inconsistent follow-up timing
            - Generic, non-personalized outreach
            - Manual CRM data entry consuming 2-3 hours daily
            - Low email response rates (12%)
            - Lost deals due to forgotten follow-ups
            
            The Solution:
            TechCorp implemented Friend AI's intelligent sales automation platform, which provided:
            - Automated, AI-powered follow-up scheduling
            - Personalized message generation based on prospect context
            - Seamless Salesforce integration
            - Sentiment analysis for engagement tracking
            
            The Results:
            Within 90 days of implementation, TechCorp achieved:
            - 40% increase in close rates (from 18% to 25.2%)
            - 3x improvement in email response rates (12% to 36%)
            - 250+ hours saved per month across the team
            - $2.4M in additional revenue attributed to improved follow-up
            
            "Friend AI transformed how our team works. We're closing more deals with less manual
            effort, and our reps can focus on relationships instead of administrative tasks."
            - Sarah Chen, VP of Sales, TechCorp
            """
        
        test_input = {
            "content": content,
            "content_type": "case_study",
            "target_keywords": "sales automation, AI sales, close rates, sales productivity, B2B sales",
            "brand_guidelines": "Professional, data-driven, customer-focused. Emphasize ROI and quantifiable results."
        }
        
        start_time = time.time()
        
        try:
            self.log("Starting CREW 3...", "INFO")
            crew = ReviewPolishCrew()
            
            # Run with retry logic
            result = self.retry_with_backoff(
                lambda: crew.crew().kickoff(inputs=test_input)
            )
            
            elapsed = time.time() - start_time
            
            self.log(f"CREW 3 COMPLETED in {elapsed/60:.1f} minutes", "SUCCESS")
            
            # Save output
            output_file = self.output_dir / "crew3_result.txt"
            with open(output_file, "w") as f:
                f.write(str(result.raw if hasattr(result, 'raw') else result))
            
            self.log(f"Output saved to: {output_file}", "INFO")
            
            # Track tools used
            tools_used = [
                "AccuracyChecker", "ConsistencyValidator", "ReadabilityAnalyzer", "LinkValidator",
                "ToneAnalyzer", "MessagingAligner", "PersonaValidator", "ComplianceChecker",
                "KeywordOptimizer", "MetadataGenerator", "CTAEnhancer", "FormatOptimizer"
            ]
            self.tools_tested.update(tools_used)
            
            crew3_result = {
                "status": "PASSED",
                "time": elapsed,
                "output_size": len(str(result)),
                "tools_tested": tools_used
            }
            
            self.test_results["crews"]["crew3"] = crew3_result
            
            return {"success": True, "result": result, "time": elapsed}
            
        except Exception as e:
            elapsed = time.time() - start_time
            self.log(f"CREW 3 FAILED after {elapsed/60:.1f} minutes: {e}", "ERROR")
            
            import traceback
            error_details = traceback.format_exc()
            self.log(f"Error details:\n{error_details}", "ERROR")
            
            self.test_results["crews"]["crew3"] = {
                "status": "FAILED",
                "time": elapsed,
                "error": str(e)
            }
            self.test_results["errors"].append({
                "crew": "CREW3",
                "error": str(e),
                "traceback": error_details
            })
            
            return {"success": False, "error": str(e), "time": elapsed}
    
    def run_full_system_test(self):
        """Run complete end-to-end system test"""
        
        print("\n" + "="*80)
        print("üöÄ FULL SYSTEM INTEGRATION TEST")
        print("="*80)
        print("üìã Testing: All 3 crews, 10 agents, 38 tools")
        print("‚è±Ô∏è  Expected time: 1.7 - 2.5 hours")
        print("üí∞ Expected cost: $0.40 - $0.60")
        print("="*80 + "\n")
        
        overall_start = time.time()
        
        # Test CREW 1
        crew1_result = self.test_crew1_full()
        
        # Test CREW 2 (only if CREW 1 passed)
        if crew1_result["success"]:
            crew2_result = self.test_crew2_full(crew1_result)
        else:
            self.log("Skipping CREW 2 (CREW 1 failed)", "WARNING")
            crew2_result = {"success": False, "skipped": True}
        
        # Test CREW 3 (only if CREW 2 passed)
        if crew2_result.get("success"):
            crew3_result = self.test_crew3_full(crew2_result)
        else:
            self.log("Skipping CREW 3 (CREW 2 failed)", "WARNING")
            crew3_result = {"success": False, "skipped": True}
        
        # Final summary
        total_time = time.time() - overall_start
        self.test_results["end_time"] = datetime.now().isoformat()
        self.test_results["total_time"] = total_time
        self.test_results["tools_tested_count"] = len(self.tools_tested)
        
        self.print_final_report()
        
        # Save full report
        report_file = self.output_dir / f"test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, "w") as f:
            json.dump({
                **self.test_results,
                "tools_tested": list(self.tools_tested)
            }, f, indent=2)
        
        self.log(f"\nFull report saved to: {report_file}", "INFO")
        
        # Return success status
        all_passed = all([
            crew1_result["success"],
            crew2_result.get("success", False),
            crew3_result.get("success", False)
        ])
        
        return all_passed
    
    def print_final_report(self):
        """Print comprehensive test report"""
        
        print("\n\n" + "="*80)
        print("üìä FINAL TEST REPORT")
        print("="*80)
        
        # Crew results
        for crew_name, result in self.test_results["crews"].items():
            status_icon = "‚úÖ" if result["status"] == "PASSED" else "‚ùå"
            time_str = f"{result['time']/60:.1f}m" if result.get("time") else "N/A"
            print(f"{status_icon} {crew_name.upper():8} {result['status']:8} Time: {time_str}")
        
        print("-" * 80)
        
        # Total time
        total_time = self.test_results.get("total_time", 0)
        print(f"‚è±Ô∏è  TOTAL TIME: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)")
        
        # Tools tested
        print(f"üîß TOOLS TESTED: {len(self.tools_tested)}/38")
        
        # Errors
        if self.test_results["errors"]:
            print(f"\n‚ùå ERRORS: {len(self.test_results['errors'])}")
            for error in self.test_results["errors"]:
                print(f"   - {error['crew']}: {error['error'][:100]}...")
        
        # Success status
        print("="*80)
        all_passed = all(
            result["status"] == "PASSED" 
            for result in self.test_results["crews"].values()
        )
        
        if all_passed:
            print("‚úÖ ALL TESTS PASSED - System validated for production!")
        else:
            failed_crews = [
                name for name, result in self.test_results["crews"].items()
                if result["status"] != "PASSED"
            ]
            print(f"‚ùå TESTS FAILED: {', '.join(failed_crews)}")
            print("üîß Review errors above and fix before proceeding")
        
        print("="*80 + "\n")


def main():
    """Run the full system test"""
    
    runner = SystemTestRunner()
    success = runner.run_full_system_test()
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
